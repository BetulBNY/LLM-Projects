{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9fbf773",
   "metadata": {},
   "source": [
    "## Tokenizing with code\n",
    "\n",
    "https://platform.openai.com/tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2050c6fe",
   "metadata": {},
   "source": [
    "#### What Tiktoken Is?\n",
    "\n",
    "* Tiktoken is a tokenizer library used for OpenAI models (GPT-3, GPT-4, GPT-5).\n",
    "* Its main purpose: convert text into tokens and tokens back into text efficiently.\n",
    "* Tokens are the basic units the model understands, often smaller than words.\n",
    "* Example:\n",
    " \"Hello, world!\" → [\"Hello\", \",\", \" world\", \"!\"] (simplified)\n",
    " /// Each token has an integer ID in the model’s vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b20a4a",
   "metadata": {},
   "source": [
    "#### Why Tokenization Matters?\n",
    "Large Language Models (LLMs) don’t operate on plain text—they work on tokens, which are mapped to vectors (embeddings).\n",
    "* Tokens: atomic pieces of text (subwords, words, characters)\n",
    "* Vocabulary: the set of all tokens the model knows\n",
    "* IDs: each token has a unique numeric ID → input to the neural network\n",
    "* Tiktoken handles the mapping: Text -> Tokens -> Token IDs -> Embeddings -> Model\n",
    "* And also the reverse: Model output IDs -> Tokens -> Text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9018ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4.1-mini\")\n",
    "\n",
    "tokens = encoding.encode(\"Hi my name is Betül and I like purple!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b385741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12194, 922, 1308, 382, 10559, 13595, 326, 357, 1299, 37896, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f2ac68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12194 : Hi\n",
      "922 :  my\n",
      "1308 :  name\n",
      "382 :  is\n",
      "10559 :  Bet\n",
      "13595 : ül\n",
      "326 :  and\n",
      "357 :  I\n",
      "1299 :  like\n",
      "37896 :  purple\n",
      "0 : !\n"
     ]
    }
   ],
   "source": [
    "for token_id in tokens:\n",
    "    token_text = encoding.decode([token_id])\n",
    "    print(f\"{token_id} : {token_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e17d3e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Bet'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.decode([10559])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aae7003b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Sunday'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.decode([10560])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bny",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
